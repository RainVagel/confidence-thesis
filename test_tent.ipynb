{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import Constraint\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "#this function just clips values to a range (elementwise)\n",
    "class Between(Constraint):\n",
    "    def __init__(self, min_value, max_value):\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "\n",
    "    def __call__(self, w):        \n",
    "        return K.clip(w, self.min_value, self.max_value)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'min_value': self.min_value,\n",
    "                'max_value': self.max_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers import Layer\n",
    "from keras.layers import activations\n",
    "from keras.layers import initializers\n",
    "from keras.layers import regularizers\n",
    "from keras.layers import constraints\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from  keras.engine.base_layer import InputSpec\n",
    "from keras.utils.generic_utils import to_list\n",
    "\n",
    "class Tent(Layer):\n",
    "    \"\"\"Tent activation Unit.\n",
    "    It follows:\n",
    "    `f(x) =  max( 0, theta -|x|) ,\n",
    "\n",
    "    where `theta` is a learned array with the same shape as x.\n",
    "    # Input shape\n",
    "        Arbitrary. Use the keyword argument `input_shape`\n",
    "        (tuple of integers, does not include the samples axis)\n",
    "        when using this layer as the first layer in a model.\n",
    "    # Output shape\n",
    "        Same shape as the input.\n",
    "    # Arguments\n",
    "        theta_initializer: initializer function for the weights.\n",
    "        theta_regularizer: L2 regularization strenth\n",
    "        theta_max: highest allowed value for theta (min value is set to 0.05)\n",
    "        shared_axes: the axes along which to share learnable\n",
    "            parameters for the activation function.\n",
    "            For example, if the incoming feature maps\n",
    "            are from a 2D convolution\n",
    "            with output shape `(batch, height, width, channels)`,\n",
    "            and you wish to share parameters across space\n",
    "            so that each filter only has one set of parameters,\n",
    "            set `shared_axes=[1, 2]`.\n",
    "    # References\n",
    "    https://arxiv.org/pdf/1908.02435.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 theta_regularizer=0.12,\n",
    "                 theta_max=1.0,\n",
    "                 shared_axes=None,\n",
    "                 **kwargs):\n",
    "        super(Tent, self).__init__(**kwargs)\n",
    "        self.supports_masking = True # Do not know what this does, just let it be\n",
    "        self.theta_initializer = initializers.Ones() #see article\n",
    "        self.theta_regularizer = regularizers.l2(theta_regularizer) # I interpreted \"weight decay\" as l2, not l1 \n",
    "        self.theta_constraint = Between(min_value=0.05,max_value=theta_max)\n",
    "\n",
    "        if shared_axes is None:\n",
    "            self.shared_axes = None\n",
    "        else:\n",
    "            self.shared_axes = to_list(shared_axes, allow_tuple=True)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        param_shape = list(input_shape[1:])\n",
    "        self.param_broadcast = [False] * len(param_shape)\n",
    "        if self.shared_axes is not None:\n",
    "            for i in self.shared_axes:\n",
    "                param_shape[i - 1] = 1\n",
    "                self.param_broadcast[i - 1] = True\n",
    "        self.theta = self.add_weight(shape=param_shape,\n",
    "                                     name='theta',\n",
    "                                     initializer=self.theta_initializer,\n",
    "                                     regularizer=self.theta_regularizer,\n",
    "                                     constraint=self.theta_constraint)\n",
    "        # Set input spec\n",
    "        axes = {}\n",
    "        if self.shared_axes:\n",
    "            for i in range(1, len(input_shape)):\n",
    "                if i not in self.shared_axes:\n",
    "                    axes[i] = input_shape[i]\n",
    "        self.input_spec = InputSpec(ndim=len(input_shape), axes=axes)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        pos = K.relu(self.theta - K.abs(inputs))\n",
    "        return pos \n",
    "\n",
    "    #TODO: what is this config for? Proabably should update this to add \"theta_max\"\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'theta_initializer': initializers.serialize(self.theta_initializer),\n",
    "            'theta_regularizer': regularizers.serialize(self.theta_regularizer),\n",
    "            'shared_axes': self.shared_axes\n",
    "        }\n",
    "        base_config = super(Tent, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets try to test the froward pass\n",
    "#TODO: maybe make it a graph? Anyway, who cares, we proved it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.19999999 0.6        1.\n",
      "  0.6        0.19999999 0.         0.        ]\n",
      " [0.         0.12       0.33999997 0.56       0.78       1.\n",
      "  0.78       0.56       0.33999997 0.12      ]]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "inp = Input(shape=(10,))\n",
    "out = Tent()(inp)\n",
    "model = Model(inp, out)\n",
    "\n",
    "output = model.predict(np.stack([np.arange(-2.0,2.0,0.4),np.arange(-1.1,1.1,0.22)]))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see if thetas can be shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 3.4885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd7b8a4110>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100)) \n",
    "model.add(Tent(shared_axes=[0]))  #returns a list of 1 value only\n",
    "#model.add(Tent()) #returns a list of 100 vals\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "model.fit(np.random.random((100,100)),np.random.random((100,1)),epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.9961924], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try it with conv2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 8.3261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcd5b372a90>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(3,(2,2),padding=\"valid\", input_shape=(2,6,3))) \n",
    "model.add(Tent(shared_axes=[0,1,2]))  #returns a list of 1 value only\n",
    "#model.add(Tent(shared_axes=[1,2]))  # returns 1 value per filter\n",
    "#model.add(Tent()) #returns one val per output\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam')\n",
    "model.fit(np.random.random((100,2,6,3)),to_categorical(np.random.choice(range(10),100)),epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[1.       , 0.9963166, 0.9974665]]], dtype=float32)]\n",
      "the shape of tent   (1, 1, 1, 3)\n",
      "the shape of output featuer maps  (?, 1, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[1].get_weights())\n",
    "print(\"the shape of tent  \", np.shape(model.layers[1].get_weights()))\n",
    "print(\"the shape of output featuer maps \", np.shape(model.layers[1].output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: test adding constraint to TENT works\n",
    "(no idea how to do it properly. train something and see that boundaries never go beyond?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: test regularization works \n",
    "(put mad regularization and see it will give widhts 0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
